{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Windows 10\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Windows 10\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Landmarks with filled, filtered data and distances saved to selected_pose_landmarks_filtered_with_distances.csv\n",
      "Average Left Stance Time: 0.19509202453987734 seconds\n",
      "Average Right Stance Time: 0.22824074074074074 seconds\n",
      "Average Left Swing Time: 0.1605316973415133 seconds\n",
      "Average Right Swing Time: 0.17972027972027968 seconds\n",
      "Average Left Step Time: 0.3556237218813906 seconds\n",
      "Average Right Step Time: 0.4076923076923077 seconds\n",
      "Average Double Support Time: 2.16 seconds\n",
      "Preparing to delete: selected_pose_landmarks_filtered_with_distances.csv\n",
      "Deleted selected_pose_landmarks_filtered_with_distances.csv\n",
      "Results successfully saved to yy.csv\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.interpolate import CubicSpline\n",
    "from scipy.signal import butter, filtfilt\n",
    "import pandas.api.types as ptypes\n",
    "from scipy.signal import find_peaks, argrelextrema\n",
    "import os\n",
    "\n",
    "# Calculate stance times for left and right feet\n",
    "fps = 30  # Replace with the actual FPS of your video\n",
    "\n",
    "\n",
    "# Function Definitions\n",
    "\n",
    "def calculate_step_time(heel_strikes, fps):\n",
    "    step_times = []\n",
    "    # We need at least two heel strikes to calculate step time\n",
    "    if len(heel_strikes) > 1:\n",
    "        for i in range(len(heel_strikes) - 1):\n",
    "            # Step time: from n-th heel strike to (n+1)-th heel strike\n",
    "            step_time = (heel_strikes[i+1] - heel_strikes[i]) / fps\n",
    "            step_times.append(step_time)\n",
    "    return np.mean(step_times) if step_times else None\n",
    "\n",
    "\n",
    "def calculate_stance_time(heel_strikes, toe_offs, fps):\n",
    "    stance_times = []\n",
    "    for heel_strike, toe_off in zip(heel_strikes, toe_offs):\n",
    "        # Assuming heel_strike comes before toe_off, which is typical in gait cycles.\n",
    "        if toe_off > heel_strike:\n",
    "            stance_time = (toe_off - heel_strike) / fps\n",
    "            stance_times.append(stance_time)\n",
    "    return np.mean(stance_times) if stance_times else None\n",
    "\n",
    "\n",
    "# Function to calculate swing time based on heel strikes and toe-offs\n",
    "def calculate_swing_time(heel_strikes, toe_offs, fps):\n",
    "    swing_times = []\n",
    "    # Ensure that there is at least one toe-off followed by another heel strike\n",
    "    if len(toe_offs) > 0 and len(heel_strikes) > 1:\n",
    "        for i in range(len(toe_offs)):\n",
    "            if i+1 < len(heel_strikes):\n",
    "                # Swing time: from n-th toe-off to (n+1)-th heel strike\n",
    "                swing_time = (heel_strikes[i+1] - toe_offs[i]) / fps\n",
    "                swing_times.append(swing_time)\n",
    "    return np.mean(swing_times) if swing_times else None\n",
    "\n",
    "# Define a function to find local maxima for heel strikes and minima for toe-offs\n",
    "def find_heel_strike_and_toe_off(distances):\n",
    "    # Find local maxima for heel strikes\n",
    "    heel_strikes = find_peaks(distances)[0]\n",
    "    # Find local minima for toe-offs\n",
    "    toe_offs = argrelextrema(distances.values, np.less)[0]\n",
    "    return heel_strikes, toe_offs\n",
    "\n",
    "# Function to calculate double support time\n",
    "def calculate_double_support_time(heel_strikes_one_leg, toe_offs_contralateral_leg, fps):\n",
    "    double_support_times = []\n",
    "    # Iterate through the smaller list of events to ensure matching pairs\n",
    "    min_events = min(len(heel_strikes_one_leg), len(toe_offs_contralateral_leg))\n",
    "    if min_events > 0:\n",
    "        for i in range(min_events - 1):\n",
    "            # Double support time: from n-th toe-off of one leg to (n+1)-th heel strike of the opposite leg\n",
    "            if toe_offs_contralateral_leg[i] < heel_strikes_one_leg[i+1]:\n",
    "                double_support_time = (heel_strikes_one_leg[i+1] - toe_offs_contralateral_leg[i]) / fps\n",
    "                double_support_times.append(double_support_time)\n",
    "    return np.mean(double_support_times) if double_support_times else None\n",
    "\n",
    "\n",
    "def apply_butterworth_lowpass_filter(data, order=10, cutoff_frequency=0.1752):\n",
    "    # Calculate the Nyquist frequency\n",
    "    nyquist_frequency = 0.5\n",
    "    # Calculate the cutoff frequency as a fraction of the Nyquist frequency\n",
    "    normalized_cutoff = cutoff_frequency / nyquist_frequency\n",
    "    # Get the filter coefficients\n",
    "    b, a = butter(order, normalized_cutoff, btype='low', analog=False)\n",
    "    # Apply the filter\n",
    "    filtered_data = filtfilt(b, a, data)\n",
    "    return filtered_data\n",
    "\n",
    "def fill_gaps_with_interpolation(column):\n",
    "    # Indices of available and missing data\n",
    "    available_data_idx = np.where(~np.isnan(column))[0]\n",
    "    missing_data_idx = np.where(np.isnan(column))[0]\n",
    "    \n",
    "    # If there are no missing values or only a single value, return the column as is\n",
    "    if len(missing_data_idx) == 0 or len(available_data_idx) < 2:\n",
    "        return column\n",
    "\n",
    "# Function to calculate 3D distance between two points.\n",
    "def calculate_3d_distance(x1, y1, z1, x2, y2, z2):\n",
    "    return np.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2 + (z2 - z1) ** 2)\n",
    "\n",
    "# Initialize MediaPipe Pose.\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(static_image_mode=False, model_complexity=1, enable_segmentation=False, smooth_landmarks=True)\n",
    "\n",
    "# Video input from file on PC instead of webcam.\n",
    "video_path = \"F:\\\\Download Folder\\\\modelwalking.mp4\"  # Replace with your video file path.\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Specify the landmarks you want to save.\n",
    "landmarks_of_interest = {\n",
    "    23: 'left_hip',\n",
    "    24: 'right_hip',\n",
    "    31: 'left_foot_index',\n",
    "    32: 'right_foot_index'\n",
    "}\n",
    "\n",
    "# Prepare data storage for CSV.\n",
    "columns = [landmarks_of_interest[i] + '_x' for i in landmarks_of_interest] + \\\n",
    "          [landmarks_of_interest[i] + '_y' for i in landmarks_of_interest] + \\\n",
    "          [landmarks_of_interest[i] + '_z' for i in landmarks_of_interest] + \\\n",
    "          [landmarks_of_interest[i] + '_visibility' for i in landmarks_of_interest]\n",
    "landmark_data = []\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert the BGR image to RGB and process it with MediaPipe Pose.\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = pose.process(frame_rgb)\n",
    "\n",
    "    # Check if any landmarks are detected and extract them.\n",
    "    if results.pose_landmarks:\n",
    "        # Extract visibility of feet\n",
    "        left_foot_visibility = results.pose_landmarks.landmark[31].visibility\n",
    "        right_foot_visibility = results.pose_landmarks.landmark[32].visibility\n",
    "\n",
    "        frame_landmarks = []\n",
    "        for idx, landmark_name in landmarks_of_interest.items():\n",
    "            if (landmark_name == 'left_foot_index' and left_foot_visibility < 0.2) or \\\n",
    "               (landmark_name == 'right_foot_index' and right_foot_visibility < 0.2):\n",
    "                # If visibility is low, append NaN\n",
    "                frame_landmarks.extend([np.nan, np.nan, np.nan, np.nan])\n",
    "            else:\n",
    "                # Otherwise, append the actual landmark data\n",
    "                landmark = results.pose_landmarks.landmark[idx]\n",
    "                frame_landmarks.extend([landmark.x, landmark.y, landmark.z, landmark.visibility])\n",
    "                \n",
    "        landmark_data.append(frame_landmarks)\n",
    "\n",
    "# Release the video file.\n",
    "cap.release()\n",
    "\n",
    "\n",
    "# Convert the landmark data into a pandas DataFrame\n",
    "df = pd.DataFrame(landmark_data, columns=columns)\n",
    "\n",
    "# Interpolate missing values and apply Butterworth filter for each column\n",
    "for col in df.columns:\n",
    "    if ptypes.is_numeric_dtype(df[col]):\n",
    "        df[col] = fill_gaps_with_interpolation(df[col].values)\n",
    "        df[col] = apply_butterworth_lowpass_filter(df[col].values)\n",
    "\n",
    "# Calculate 3D distances after interpolation and filtering\n",
    "df['right_hip_to_left_foot_distance'] = calculate_3d_distance(\n",
    "    df['right_hip_x'], df['right_hip_y'], df['right_hip_z'],\n",
    "    df['left_foot_index_x'], df['left_foot_index_y'], df['left_foot_index_z']\n",
    ")\n",
    "\n",
    "df['right_hip_to_right_foot_distance'] = calculate_3d_distance(\n",
    "    df['right_hip_x'], df['right_hip_y'], df['right_hip_z'],\n",
    "    df['right_foot_index_x'], df['right_foot_index_y'], df['right_foot_index_z']\n",
    ")\n",
    "\n",
    "df['left_hip_to_left_foot_distance'] = calculate_3d_distance(\n",
    "    df['left_hip_x'], df['left_hip_y'], df['left_hip_z'],\n",
    "    df['left_foot_index_x'], df['left_foot_index_y'], df['left_foot_index_z']\n",
    ")\n",
    "\n",
    "df['left_hip_to_right_foot_distance'] = calculate_3d_distance(\n",
    "    df['left_hip_x'], df['left_hip_y'], df['left_hip_z'],\n",
    "    df['right_foot_index_x'], df['right_foot_index_y'], df['right_foot_index_z']\n",
    ")\n",
    "\n",
    "\n",
    "# Calculate heel strike and toe-off events for the left and right feet\n",
    "df['left_heel_strike_events'] = np.nan\n",
    "df['right_heel_strike_events'] = np.nan\n",
    "df['left_toe_off_events'] = np.nan\n",
    "df['right_toe_off_events'] = np.nan\n",
    "\n",
    "left_heel_strikes, left_toe_offs = find_heel_strike_and_toe_off(df['left_hip_to_left_foot_distance'])\n",
    "right_heel_strikes, right_toe_offs = find_heel_strike_and_toe_off(df['right_hip_to_right_foot_distance'])\n",
    "\n",
    "df.loc[left_heel_strikes, 'left_heel_strike_events'] = df.loc[left_heel_strikes, 'left_hip_to_left_foot_distance']\n",
    "df.loc[left_toe_offs, 'left_toe_off_events'] = df.loc[left_toe_offs, 'left_hip_to_left_foot_distance']\n",
    "df.loc[right_heel_strikes, 'right_heel_strike_events'] = df.loc[right_heel_strikes, 'right_hip_to_right_foot_distance']\n",
    "df.loc[right_toe_offs, 'right_toe_off_events'] = df.loc[right_toe_offs, 'right_hip_to_right_foot_distance']\n",
    "\n",
    "\n",
    "# Save the DataFrame to a CSV file.\n",
    "csv_path = 'selected_pose_landmarks_filtered_with_distances.csv'  # Modify as needed.\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"Landmarks with filled, filtered data and distances saved to {csv_path}\")\n",
    "\n",
    "left_stance_time = calculate_stance_time(left_heel_strikes, left_toe_offs, fps)\n",
    "right_stance_time = calculate_stance_time(right_heel_strikes, right_toe_offs, fps)\n",
    "\n",
    "print(f\"Average Left Stance Time: {left_stance_time} seconds\")\n",
    "print(f\"Average Right Stance Time: {right_stance_time} seconds\")\n",
    "\n",
    "\n",
    "left_swing_time = calculate_swing_time(left_heel_strikes, left_toe_offs, fps)\n",
    "right_swing_time = calculate_swing_time(right_heel_strikes, right_toe_offs, fps)\n",
    "\n",
    "print(f\"Average Left Swing Time: {left_swing_time} seconds\")\n",
    "print(f\"Average Right Swing Time: {right_swing_time} seconds\")\n",
    "\n",
    "\n",
    "left_step_time = calculate_step_time(left_heel_strikes, fps)\n",
    "right_step_time = calculate_step_time(right_heel_strikes, fps)\n",
    "\n",
    "print(f\"Average Left Step Time: {left_step_time} seconds\")\n",
    "print(f\"Average Right Step Time: {right_step_time} seconds\")\n",
    "\n",
    "\n",
    "\n",
    "double_support_time_left_then_right = calculate_double_support_time(left_heel_strikes, right_toe_offs, fps)\n",
    "double_support_time_right_then_left = calculate_double_support_time(right_heel_strikes, left_toe_offs, fps)\n",
    "\n",
    "# Calculate the average of both double support times\n",
    "average_double_support_time = np.nanmean([double_support_time_left_then_right, double_support_time_right_then_left])\n",
    "\n",
    "print(f\"Average Double Support Time: {average_double_support_time} seconds\")\n",
    "\n",
    "# Before deletion, print the file path to confirm\n",
    "print(f\"Preparing to delete: {csv_path}\")\n",
    "\n",
    "# Delete the CSV file\n",
    "if os.path.exists(csv_path):\n",
    "    os.remove(csv_path)\n",
    "    print(f\"Deleted {csv_path}\")\n",
    "else:\n",
    "    print(f\"The file {csv_path} does not exist.\")\n",
    "\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame()\n",
    "results_df['Average Left Stance Time'] = [left_stance_time]\n",
    "results_df['Average Right Stance Time'] = [right_stance_time]\n",
    "results_df['Average Left Swing Time'] = [left_swing_time]\n",
    "results_df['Average Right Swing Time'] = [right_swing_time]\n",
    "results_df['Average Left Step Time'] = [left_step_time]\n",
    "results_df['Average Right Step Time'] = [right_step_time]\n",
    "results_df['Average Double Support Time'] = [average_double_support_time]\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "results_df.to_csv(\"yy.csv\", index=False)\n",
    "\n",
    "print(\"Results successfully saved to yy.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
